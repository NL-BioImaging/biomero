<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>BIOMERO - the OMERO Slurm Client library &mdash; Omero Slurm Client 1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Cellprofiler tutorial" href="tutorial_link.html" />
    <link rel="prev" title="Welcome to Omero Slurm Client’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Omero Slurm Client
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">BIOMERO - the OMERO Slurm Client library</a></li>
<li class="toctree-l1"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="#quickstart">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="#prerequisites-getting-started">Prerequisites &amp; Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#slurm-requirements">Slurm Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="#omero-requirements">OMERO Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="#getting-started">Getting Started</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#omero-scripts">OMERO.scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="#see-the-tutorials">See the tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="#ssh">SSH</a></li>
<li class="toctree-l1"><a class="reference internal" href="#slurmclient-class">SlurmClient class</a></li>
<li class="toctree-l1"><a class="reference internal" href="#slurm-config-ini">slurm-config.ini</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-add-an-existing-workflow">How to add an existing workflow</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#workflow-metadata-via-descriptor-json">Workflow metadata via descriptor.json</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#schema">Schema</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#multiple-versions">Multiple versions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#i-o">I/O</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#wrapper-py">Wrapper.py</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-add-your-new-custom-workflow">How to add your new custom workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="#slurm-jobs">Slurm jobs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#generating-jobs">Generating jobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-add-your-own-slurm-job">How to add your own Slurm job</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#parameters">Parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#batching">Batching</a></li>
<li class="toctree-l1"><a class="reference internal" href="#using-the-gpu-on-slurm">Using the GPU on Slurm</a></li>
<li class="toctree-l1"><a class="reference internal" href="#transfering-data">Transfering data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorial_link.html">Cellprofiler tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_link.html#cellexpansion-tutorial">CellExpansion tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_link.html#local-slurm-tutorial">Local Slurm tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_link.html#google-cloud-slurm-tutorial">Google Cloud Slurm tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">omero_slurm_client</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Omero Slurm Client</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">BIOMERO - the OMERO Slurm Client library</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/readme_link.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="biomero-the-omero-slurm-client-library">
<h1>BIOMERO - the OMERO Slurm Client library<a class="headerlink" href="#biomero-the-omero-slurm-client-library" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://opensource.org/licenses/Apache-2.0"><img alt="License" src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" /></a> <a class="reference external" href="https://zenodo.org/badge/latestdoi/638954891"><img alt="DOI" src="https://zenodo.org/badge/638954891.svg" /></a> <img alt="Python" src="https://img.shields.io/badge/Python-3.6-blue.svg" /> <img alt="Slurm" src="https://img.shields.io/badge/Slurm-21.08.6-blue.svg" /> <img alt="OMERO" src="https://img.shields.io/badge/OMERO-5.6.8-blue.svg" /> <a class="reference external" href="https://fair-software.eu"><img alt="fair-software.eu" src="https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8B%20%20%E2%97%8F%20%20%E2%97%8F-yellow" /></a> <a class="reference external" href="https://bestpractices.coreinfrastructure.org/projects/7530"><img alt="OpenSSF Best Practices" src="https://bestpractices.coreinfrastructure.org/projects/7530/badge" /></a> <a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-client/actions/workflows/sphinx.yml"><img alt="Sphinx build" src="https://github.com/NL-BioImaging/omero-slurm-client/actions/workflows/sphinx.yml/badge.svg?branch=main" /></a> <a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-client/actions/workflows/pages/pages-build-deployment"><img alt="pages-build-deployment" src="https://github.com/NL-BioImaging/omero-slurm-client/actions/workflows/pages/pages-build-deployment/badge.svg" /></a></p>
<p>This library is to be used within BIOMERO (an extension to OMERO), together with the OMERO Slurm Scripts we also provide.</p>
<p>Together, BIOMERO allows you to run BioImage analysis workflows directly from OMERO on a Slurm cluster, through SSH.</p>
<p>The package includes the <code class="docutils literal notranslate"><span class="pre">SlurmClient</span></code> class, which extends the Fabric library’s <code class="docutils literal notranslate"><span class="pre">Connection</span></code> class to provide <strong>SSH-based connectivity</strong> and interaction with a Slurm cluster. The package enables users to submit jobs, monitor job status, retrieve job output, and perform other Slurm-related tasks. Additionally, the package offers functionality for configuring and managing paths to Slurm data and Singularity images, as well as specific image models and their associated repositories.</p>
<p>Overall, the <code class="docutils literal notranslate"><span class="pre">omero_slurm_client</span></code> package simplifies the integration of Slurm functionality within the OMERO platform and provides an efficient workflow for working with Slurm clusters.</p>
</div>
<div class="section" id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h1>
<p>In the figure below we show our <strong>BIOMERO</strong> framework, for <strong>B</strong>io<strong>I</strong>mage analysis in <strong>OMERO</strong>.</p>
<p>BIOMERO consists of this Python library (OMERO Slurm Client) and the integrations within OMERO, currently through our <a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts">OMERO scripts</a>.</p>
<p><img alt="OMERO-Figure1_Overview_v5" src="https://github.com/NL-BioImaging/omero-slurm-client/assets/68958516/ff437ed2-d4b7-48b4-a7e3-12f1dbf00981" /></p>
</div>
<div class="section" id="quickstart">
<h1>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline"></a></h1>
<p>For a quick overview of what this library can do for you, we can install an example setup locally with Docker:</p>
<ol class="arabic simple">
<li><p>Setup a local OMERO w/ this library:</p>
<ul class="simple">
<li><p>Follow Quickstart of https://github.com/TorecLuik/docker-example-omero-grid-amc</p></li>
</ul>
</li>
<li><p>Setup a local Slurm w/ SSH access:</p>
<ul class="simple">
<li><p>Follow Quickstart of https://github.com/TorecLuik/slurm-docker-cluster</p></li>
</ul>
</li>
<li><p>Upload some data with OMERO.insight to <code class="docutils literal notranslate"><span class="pre">localhost</span></code> server</p></li>
<li><p>Try out some scripts from https://github.com/NL-BioImaging/omero-slurm-scripts (already installed in step 1!):</p>
<ol class="arabic simple">
<li><p>Run script <code class="docutils literal notranslate"><span class="pre">slurm/init/SLURM</span> <span class="pre">Init</span> <span class="pre">environment...</span></code></p></li>
<li><p>Get a coffee or something. This will take at least 10 min to download all the workflow images. Maybe write a nice review on <code class="docutils literal notranslate"><span class="pre">image.sc</span></code> of this software, or here on the <code class="docutils literal notranslate"><span class="pre">Discussions</span></code> tab of Github.</p></li>
<li><p>Select your image / dataset and run script <code class="docutils literal notranslate"><span class="pre">slurm/workflows/SLURM</span> <span class="pre">Run</span> <span class="pre">Workflow...</span></code></p>
<ul class="simple">
<li><p>Select at least one of the <code class="docutils literal notranslate"><span class="pre">Select</span> <span class="pre">how</span> <span class="pre">to</span> <span class="pre">import</span> <span class="pre">your</span> <span class="pre">results</span></code>, e.g. change <code class="docutils literal notranslate"><span class="pre">Import</span> <span class="pre">into</span> <span class="pre">NEW</span> <span class="pre">Dataset</span></code> text to <code class="docutils literal notranslate"><span class="pre">hello</span> <span class="pre">world</span></code></p></li>
<li><p>Select a fun workflow, e.g. <code class="docutils literal notranslate"><span class="pre">cellpose</span></code>.</p>
<ul>
<li><p>Change the <code class="docutils literal notranslate"><span class="pre">nuc</span> <span class="pre">channel</span></code> to the channel to segment (note that 0 is for grey, so 1,2,3 for RGB)</p></li>
<li><p>Uncheck the <code class="docutils literal notranslate"><span class="pre">use</span> <span class="pre">gpu</span></code> (step 2 doesn’t come with GPU support)</p></li>
</ul>
</li>
<li><p>Refresh your OMERO <code class="docutils literal notranslate"><span class="pre">Explore</span></code> tab to see your <code class="docutils literal notranslate"><span class="pre">hello</span> <span class="pre">world</span></code> dataset with a mask image when the workflow is done.</p></li>
</ul>
</li>
</ol>
</li>
</ol>
</div>
<div class="section" id="prerequisites-getting-started">
<h1>Prerequisites &amp; Getting Started<a class="headerlink" href="#prerequisites-getting-started" title="Permalink to this headline"></a></h1>
<div class="section" id="slurm-requirements">
<h2>Slurm Requirements<a class="headerlink" href="#slurm-requirements" title="Permalink to this headline"></a></h2>
<p>Note: This library has only been tested on Slurm versions 21.08.6 and 22.05.09 !</p>
<p>Your Slurm cluster/login node needs to have:</p>
<ol class="arabic simple">
<li><p>SSH access w/ public key (headless)</p></li>
<li><p>SCP access (generally comes with SSH)</p></li>
<li><p>7zip installed</p></li>
<li><p>Singularity/Apptainer installed</p></li>
<li><p>(Optional) Git installed, if you want your own job scripts</p></li>
</ol>
</div>
<div class="section" id="omero-requirements">
<h2>OMERO Requirements<a class="headerlink" href="#omero-requirements" title="Permalink to this headline"></a></h2>
<p>Your OMERO <em>processing</em> node needs to have:</p>
<ol class="arabic simple">
<li><p>SSH client and access to the Slurm cluster (w/ private key / headless)</p></li>
<li><p>SCP access to the Slurm cluster</p></li>
<li><p>Python3.6+</p></li>
<li><p>This library installed</p>
<ul class="simple">
<li><p>Latest release on PyPI <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">omero-slurm-client</span></code></p></li>
<li><p>or latest Github version <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">'git+https://github.com/NL-BioImaging/omero-slurm-client'</span></code></p></li>
</ul>
</li>
<li><p>Configuration setup at <code class="docutils literal notranslate"><span class="pre">/etc/slurm-config.ini</span></code></p></li>
<li><p>Requirements for some scripts: <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">ezomero==1.1.1</span> <span class="pre">tifffile==2020.9.3</span></code> and the <a class="reference external" href="https://github.com/ome/omero-cli-zarr">OMERO CLI Zarr plugin</a>.</p></li>
</ol>
<p>Your OMERO <em>server</em> node needs to have:</p>
<ol class="arabic simple">
<li><p>Some OMERO example scripts installed to interact with this library:</p>
<ul class="simple">
<li><p>My examples on github: <code class="docutils literal notranslate"><span class="pre">https://github.com/NL-BioImaging/omero-slurm-scripts</span></code></p></li>
<li><p>Install those at <code class="docutils literal notranslate"><span class="pre">/opt/omero/server/OMERO.server/lib/scripts/slurm/</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">https://github.com/NL-BioImaging/omero-slurm-scripts.git</span> <span class="pre">&lt;path&gt;/slurm</span></code></p></li>
</ul>
</li>
</ol>
<p>!!<em>NOTE</em>: Do not install <a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/Example_Minimal_Slurm_Script.py">Example Minimal Slurm Script</a> if you do not trust your users with your Slurm cluster. It has literal Command Injection for the SSH user as a <strong>FEATURE</strong>.</p>
</div>
<div class="section" id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline"></a></h2>
<p>To connect an OMERO processor to a Slurm cluster using the <code class="docutils literal notranslate"><span class="pre">omero_slurm_client</span></code> library, users can follow these steps:</p>
<ol class="arabic simple">
<li><p>Setup passwordless public key authentication between your OMERO <code class="docutils literal notranslate"><span class="pre">processor</span></code> server and your HPC server. E.g. follow  a <a class="reference external" href="https://www.ssh.com/academy/ssh/public-key-authentication">SSH tutorial</a> or <a class="reference external" href="https://linuxize.com/post/how-to-setup-passwordless-ssh-login/">this one</a>.</p>
<ul class="simple">
<li><p>You could use 1 Slurm account for all <code class="docutils literal notranslate"><span class="pre">processor</span></code> servers, and share the same private key to all of them.</p></li>
<li><p>Or you could use unique accounts, but give them all the same alias in step 2.</p></li>
</ul>
</li>
<li><p>Create a SSH config file named <code class="docutils literal notranslate"><span class="pre">config</span></code> in the <code class="docutils literal notranslate"><span class="pre">.ssh</span></code> directory of (all) the OMERO <code class="docutils literal notranslate"><span class="pre">processor</span></code> servers, within the <code class="docutils literal notranslate"><span class="pre">omero</span></code> user’s home directory (<code class="docutils literal notranslate"><span class="pre">~/.ssh/config</span></code>). This file should specify the hostname, username, port, and private key path for the Slurm cluster, under some alias. This alias we will provide to the library. We provide an example in the <a class="reference internal" href="#./resources/config"><span class="xref myst">resources</span></a> directory.</p>
<ul class="simple">
<li><p>This will allow a uniform SSH naming, and makes the connection headless; making it easy for the library.</p></li>
<li><p>Test the SSH connection manually! <code class="docutils literal notranslate"><span class="pre">ssh</span> <span class="pre">slurm</span></code> (as the omero user) should connect you to the Slurm server (given that you named it <code class="docutils literal notranslate"><span class="pre">slurm</span></code> in the <code class="docutils literal notranslate"><span class="pre">config</span></code>).</p></li>
<li><p>Congratulations! Now the servers are connected. Next, we make sure to setup the connection between OMERO and Slurm.</p></li>
</ul>
</li>
<li><p>At this point, ensure that the <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code> file is correctly configured with the necessary SSH and Slurm settings, including the host, data path, images path, and model details. Customize the configuration according to the specific Slurm cluster setup. We provide an example in the <a class="reference internal" href="#./resources/slurm-config.ini"><span class="xref myst">resources</span></a> section. To read it automatically, place this <code class="docutils literal notranslate"><span class="pre">ini</span></code> file in one of the following locations (on the OMERO <code class="docutils literal notranslate"><span class="pre">processor</span></code> server):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">/etc/slurm-config.ini</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">~/slurm-config.ini</span></code></p></li>
</ul>
</li>
<li><p>Install OMERO scripts from <a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts">OMERO Slurm Scripts</a>, e.g.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cd</span> <span class="pre">OMERO_DIST/lib/scripts</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">https://github.com/NL-BioImaging/omero-slurm-scripts.git</span> <span class="pre">slurm</span></code></p></li>
</ul>
</li>
</ol>
<p>!!<em>NOTE</em>: Do not install <a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/Example_Minimal_Slurm_Script.py">Example Minimal Slurm Script</a> if you do not trust your users with your Slurm cluster. It has literal Command Injection for the SSH user as a <strong>FEATURE</strong>.</p>
<ol class="arabic simple" start="5">
<li><p>Install OMERO Slurm Scripts requirements, e.g.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">ezomero==1.1.1</span> <span class="pre">tifffile==2020.9.3</span></code></p></li>
<li><p>the <a class="reference external" href="https://github.com/ome/omero-cli-zarr">OMERO CLI Zarr plugin</a>, e.g.
<code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">omero-cli-zarr==0.5.3</span></code> &amp;&amp; <code class="docutils literal notranslate"><span class="pre">yum</span> <span class="pre">install</span> <span class="pre">-y</span> <span class="pre">blosc-devel</span></code></p></li>
<li><p>the <a class="reference external" href="https://github.com/glencoesoftware/bioformats2raw/releases/download/v0.7.0/bioformats2raw-0.7.0.zip">bioformats2raw-0.7.0</a>, e.g. <code class="docutils literal notranslate"><span class="pre">unzip</span> <span class="pre">-d</span> <span class="pre">/opt</span> <span class="pre">bioformats2raw-0.7.0.zip</span> <span class="pre">&amp;&amp;</span> <span class="pre">export</span> <span class="pre">PATH=&quot;$PATH:/opt/bioformats2raw-0.7.0/bin&quot;</span></code></p></li>
</ul>
</li>
<li><p>To finish setting up your <code class="docutils literal notranslate"><span class="pre">SlurmClient</span></code> and Slurm server, run it once with <code class="docutils literal notranslate"><span class="pre">init_slurm=True</span></code>. This is provided in a OMERO script form at <a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/init/SLURM_Init_environment.py">init/Slurm Init environment</a> , which you just installed in previous step.</p>
<ul class="simple">
<li><p>Provide the configfile location explicitly if it is not a default one defined earlier, otherwise you can omit that field.</p></li>
<li><p>Please note the requirements for your Slurm cluster. We do not install Singularity / 7zip on your cluster for you (at the time of writing).</p></li>
<li><p>This operation will make it create the directories you provided in the <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code>, pull any described Singularity images to the server (note: might take a while), and generate (or clone from Git) any job scripts for these workflows:</p></li>
</ul>
</li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">SlurmClient</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">configfile</span><span class="o">=</span><span class="n">configfile</span><span class="p">,</span>
                            <span class="n">init_slurm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">slurmClient</span><span class="p">:</span>
    <span class="n">slurmClient</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">validate_slurm_setup</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>With the configuration files in place, you can utilize the <code class="docutils literal notranslate"><span class="pre">SlurmClient</span></code> class from the OMERO Slurm Client library to connect to the Slurm cluster over SSH, enabling the submission and management of Slurm jobs from an OMERO processor.</p>
</div>
</div>
<div class="section" id="omero-scripts">
<h1>OMERO.scripts<a class="headerlink" href="#omero-scripts" title="Permalink to this headline"></a></h1>
<p>The easiest interaction from OMERO with this library currently is through OMERO.scripts.</p>
<p>!!<em>NOTE</em>: Do not install <a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/Example_Minimal_Slurm_Script.py">Example Minimal Slurm Script</a> if you do not trust your users with your Slurm cluster. It has literal Command Injection for the SSH user as a <strong>FEATURE</strong>.</p>
<p>We have provided example OMERO scripts of how to use this in https://github.com/NL-BioImaging/omero-slurm-scripts (hopefully installed in a previous step).</p>
<p>For example, <a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/workflows/SLURM_Run_Workflow.py">workflows/Slurm Run Workflow</a> should provide an easy way to send data to Slurm, run the configured and chosen workflow, poll Slurm until jobs are done (or errors) and retrieve the results when the job is done. This workflow script uses some of the other scripts, like</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/data/_SLURM_Image_Transfer.py"><code class="docutils literal notranslate"><span class="pre">data/Slurm</span> <span class="pre">Image</span> <span class="pre">Transfer</span></code></a>: to export your selected images / dataset / screen as TIFF files to a Slurm dir.</p></li>
<li><p><a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/data/SLURM_Get_Results.py"><code class="docutils literal notranslate"><span class="pre">data/Slurm</span> <span class="pre">Get</span> <span class="pre">Results</span></code></a>: to import your Slurm job results back into OMERO as a zip, dataset or attachment.</p></li>
</ul>
<p>Other example OMERO scripts are:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/data/SLURM_Get_Update.py"><code class="docutils literal notranslate"><span class="pre">data/Slurm</span> <span class="pre">Get</span> <span class="pre">Update</span></code></a>: to run while you are waiting on a job to finish on Slurm; it will try to get a <code class="docutils literal notranslate"><span class="pre">%</span></code> progress from your job’s logfile. Depends on your job/workflow logging a <code class="docutils literal notranslate"><span class="pre">%</span></code> of course.</p></li>
<li><p><a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/workflows/SLURM_Run_Workflow_Batched.py"><code class="docutils literal notranslate"><span class="pre">workflows/Slurm</span> <span class="pre">Run</span> <span class="pre">Workflow</span> <span class="pre">Batched</span></code></a>: This will allow you to run several <code class="docutils literal notranslate"><span class="pre">workflows/Slurm</span> <span class="pre">Run</span> <span class="pre">Workflow</span></code> in parallel, by batching your input images into smaller chunks (e.g. turn 64 images into 2 batches of 32 images each). It will then poll all these jobs.</p></li>
<li><p><a class="reference external" href="https://github.com/NL-BioImaging/omero-slurm-scripts/blob/master/workflows/SLURM_CellPose_Segmentation.py"><code class="docutils literal notranslate"><span class="pre">workflows/Slurm</span> <span class="pre">CellPose</span> <span class="pre">Segmentation</span></code></a>: This is a more primitive script that only runs the actual workflow <code class="docutils literal notranslate"><span class="pre">CellPose</span></code> (if correctly configured). You will need to manually transfer data first (with <code class="docutils literal notranslate"><span class="pre">Slurm</span> <span class="pre">Image</span> <span class="pre">Transfer</span></code>) and manually retrieve data afterward (with <code class="docutils literal notranslate"><span class="pre">Slurm</span> <span class="pre">Get</span> <span class="pre">Results</span></code>).</p></li>
</ul>
<p>You are encouraged to create your own custom scripts. Do note the copy-left license enforced by OME.</p>
</div>
<div class="section" id="see-the-tutorials">
<h1>See the tutorials<a class="headerlink" href="#see-the-tutorials" title="Permalink to this headline"></a></h1>
<p>I have also provided tutorials on connecting to a Local or Cloud Slurm, and tutorials on how to add your FAIR workflows to this setup. Those can give some more insights as well.</p>
</div>
<div class="section" id="ssh">
<h1>SSH<a class="headerlink" href="#ssh" title="Permalink to this headline"></a></h1>
<p>Note: this library is built for <strong>SSH-based connections</strong>. If you could, it would be a lot easier to just have the OMERO <code class="docutils literal notranslate"><span class="pre">processor</span></code> server and the <code class="docutils literal notranslate"><span class="pre">slurm</span></code> client server be (on) the same machine: then you can just directly call <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> and other <code class="docutils literal notranslate"><span class="pre">slurm</span></code> commands from OMERO scripts and Slurm would have better access to your data.</p>
<p>This is mainly for those cases where you already have an external HPC cluster and want to connect your OMERO instance.</p>
<p>Theoretically, you could extend the <code class="docutils literal notranslate"><span class="pre">SlurmClient</span></code> class and change the <code class="docutils literal notranslate"><span class="pre">run</span></code> commands to not use SSH, but just a <code class="docutils literal notranslate"><span class="pre">subprocess</span></code>. We might implement this if we need it in the future.
But then you could also look at other Python libraries like <a class="reference external" href="https://github.com/facebookincubator/submitit">submitit</a>.</p>
</div>
<div class="section" id="slurmclient-class">
<h1>SlurmClient class<a class="headerlink" href="#slurmclient-class" title="Permalink to this headline"></a></h1>
<p>The SlurmClient class is the main entrypoint in using this library.
It is a Python class that extends the Connection class from the Fabric library. It allows connecting to and interacting with a Slurm cluster over SSH.</p>
<p>It includes attributes for specifying paths to directories for Slurm data and Singularity images, as well as specific paths, repositories, and Dockerhub information for different Singularity image models.</p>
<p>The class provides methods for running commands on the remote Slurm host, submitting jobs, checking job status, retrieving job output, and tailing log files.</p>
<p>It also offers a <code class="docutils literal notranslate"><span class="pre">from_config</span></code> class method to create a <code class="docutils literal notranslate"><span class="pre">SlurmClient</span></code> object by reading configuration parameters from a file. Overall, the class provides a convenient way to work with Slurm clusters and manage job execution and monitoring.</p>
</div>
<div class="section" id="slurm-config-ini">
<h1>slurm-config.ini<a class="headerlink" href="#slurm-config-ini" title="Permalink to this headline"></a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code> file is a configuration file used by the <code class="docutils literal notranslate"><span class="pre">omero_slurm_client</span></code> Python package to specify various settings related to SSH and Slurm. Here is a brief description of its contents:</p>
<p>[<strong>SSH</strong>]: This section contains SSH settings, including the alias for the SLURM SSH connection (host). Additional SSH configuration can be specified in the user’s SSH config file or in <code class="docutils literal notranslate"><span class="pre">/etc/fabric.yml</span></code>.</p>
<p>[<strong>SLURM</strong>]: This section includes settings specific to Slurm. It defines the paths on the SLURM entrypoint for storing data files (slurm_data_path), container image files (slurm_images_path), and Slurm job scripts (slurm_script_path). It also specifies the repository (slurm_script_repo) from which to pull the Slurm scripts.</p>
<p>[<strong>MODELS</strong>]: This section is used to define different model settings. Each model has a unique key and requires corresponding values for <code class="docutils literal notranslate"><span class="pre">&lt;key&gt;_repo</span></code> (repository containing the descriptor.json file, which will describe parameters and where to find the image), and <code class="docutils literal notranslate"><span class="pre">&lt;key&gt;_job</span></code> (jobscript name and location in the <code class="docutils literal notranslate"><span class="pre">slurm_script_repo</span></code>). The example shows settings for several segmentation models, including Cellpose, Stardist, CellProfiler, DeepCell, and ImageJ.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code> file allows users to configure paths, repositories, and other settings specific to their Slurm cluster and the <code class="docutils literal notranslate"><span class="pre">omero_slurm_client</span></code> package, providing flexibility and customization options.</p>
</div>
<div class="section" id="how-to-add-an-existing-workflow">
<h1>How to add an existing workflow<a class="headerlink" href="#how-to-add-an-existing-workflow" title="Permalink to this headline"></a></h1>
<p>To add an existing (containerized) workflow, add it to the <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code> file like in our example:</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------</span>
<span class="c1"># CELLPOSE SEGMENTATION</span>
<span class="c1"># -------------------------------------</span>
<span class="c1"># The path to store the container on the slurm_images_path</span>
<span class="na">cellpose</span><span class="o">=</span><span class="s">cellpose</span>
<span class="c1"># The (e.g. github) repository with the descriptor.json file</span>
<span class="na">cellpose_repo</span><span class="o">=</span><span class="s">https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/tree/v1.2.7</span>
<span class="c1"># The jobscript in the &#39;slurm_script_repo&#39;</span>
<span class="na">cellpose_job</span><span class="o">=</span><span class="s">jobs/cellpose.sh</span>
</pre></div>
</div>
<p>Here,</p>
<ol class="arabic simple">
<li><p>the name referenced for this workflow is <code class="docutils literal notranslate"><span class="pre">cellpose</span></code></p></li>
<li><p>the location of the container on slurm will be <code class="docutils literal notranslate"><span class="pre">&lt;slurm_images_path&gt;/cellpose</span></code></p></li>
<li><p>the code repository is <code class="docutils literal notranslate"><span class="pre">https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose</span></code></p></li>
<li><p>the specific version we want is <code class="docutils literal notranslate"><span class="pre">v1.2.7</span></code></p></li>
<li><p>the container can be found on bitbucket</p>
<ul class="simple">
<li><p>under the path given in the metadata file: <a class="reference external" href="https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/blob/v1.2.7/descriptor.json">descriptor.json</a></p></li>
</ul>
</li>
<li><p>the location of the jobscript on slurm will be <code class="docutils literal notranslate"><span class="pre">&lt;slurm_script_repo&gt;/jobs/cellpose.sh</span></code>.</p>
<ul class="simple">
<li><p>This either references a git repo, where it matches this path,</p></li>
<li><p>or it will be the location where the library will generate a jobscript (if no repo is given)</p></li>
</ul>
</li>
</ol>
<div class="section" id="workflow-metadata-via-descriptor-json">
<h2>Workflow metadata via descriptor.json<a class="headerlink" href="#workflow-metadata-via-descriptor-json" title="Permalink to this headline"></a></h2>
<p>A lot of the automation in this library is based on metadata of the workflow, provided in the source code of the workflow, specifically the <a class="reference external" href="https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/blob/v1.2.7/descriptor.json">descriptor.json</a>.</p>
<p>For example, the OMERO script UI can be generated automatically, based on this descriptor. And also, the Slurm job script can be generated automatically, based on this descriptor.</p>
<p>This metadata scheme is (based on) Cytomine / BIAFLOWS, and you can find details of it and how to create one yourself on their website, e.g. this <a class="reference external" href="https://doc.uliege.cytomine.org/dev-guide/algorithms/write-app#create-the-json-descriptor">Cytomine dev-guide</a> or this <a class="reference external" href="https://neubias-wg5.github.io/developer_guide_add_new_workflow_to_biaflows_instance.html">BIAFLOWS dev-guide</a>.</p>
<p><strong>NOTE!</strong> We do not require the <code class="docutils literal notranslate"><span class="pre">cytomine_&lt;...&gt;</span></code> authentication parameters. They are not mandatory. In fact, we ignore them. But it might be beneficial to make your workflow compatible with Cytomine as well.</p>
<div class="section" id="schema">
<h3>Schema<a class="headerlink" href="#schema" title="Permalink to this headline"></a></h3>
<p>At this point, we are using the <code class="docutils literal notranslate"><span class="pre">cytomine-0.1</span></code> <a class="reference external" href="https://doc.uliege.cytomine.org/dev-guide/algorithms/descriptor-reference">schema</a>, in the future we will also want to support other schemas, like <a class="reference external" href="https://boutiques.github.io/">Boutiques</a>, <a class="reference external" href="https://www.commonwl.org/">commonwl</a> or <a class="reference external" href="https://www.mlflow.org/docs/latest/projects.html">MLFlow</a>.</p>
<p>We will try to stay compatible with all such schemas (perhaps with less functionality because of missing metadata).</p>
<p>At this point, we do not strictly validate the schema, we just read expected fields from the <code class="docutils literal notranslate"><span class="pre">descriptor.json</span></code>.</p>
</div>
</div>
<div class="section" id="multiple-versions">
<h2>Multiple versions<a class="headerlink" href="#multiple-versions" title="Permalink to this headline"></a></h2>
<p>Note that while it is possible to have multiple versions of the same workflow on Slurm (and select the desired one in OMERO), it is not possible to configure this yet. We assume for now you only want one version to start with. You can always update this config to download a new version to Slurm.</p>
</div>
<div class="section" id="i-o">
<h2>I/O<a class="headerlink" href="#i-o" title="Permalink to this headline"></a></h2>
<p>Unless you change the <code class="docutils literal notranslate"><span class="pre">Slurm</span></code> job, the input is expected to be:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">infolder</span></code> parameter</p>
<ul>
<li><p>pointing to a folder with multiple input files/images</p></li>
</ul>
</li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">gtfolder</span></code> parameter (Optional)</p>
<ul>
<li><p>pointing to a <code class="docutils literal notranslate"><span class="pre">ground-truth</span></code> input files, generally not needed for prediction / processing purposes.</p></li>
</ul>
</li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">outfolder</span></code> parameter</p>
<ul>
<li><p>where you write all your output files (to get copied back to OMERO)</p></li>
</ul>
</li>
</ul>
<div class="section" id="wrapper-py">
<h3>Wrapper.py<a class="headerlink" href="#wrapper-py" title="Permalink to this headline"></a></h3>
<p>Note that you can also use the <a class="reference external" href="https://github.com/Neubias-WG5/W_Template/blob/master/wrapper.py">wrapper.py</a> setup from BIAFLOWS to handle the I/O for you:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">BiaflowsJob</span><span class="o">.</span><span class="n">from_cli</span><span class="p">(</span><span class="n">argv</span><span class="p">)</span> <span class="k">as</span> <span class="n">bj</span><span class="p">:</span>
        <span class="c1"># Change following to the actual problem class of the workflow</span>
        <span class="o">...</span>
        
        <span class="c1"># 1. Prepare data for workflow</span>
        <span class="n">in_imgs</span><span class="p">,</span> <span class="n">gt_imgs</span><span class="p">,</span> <span class="n">in_path</span><span class="p">,</span> <span class="n">gt_path</span><span class="p">,</span> <span class="n">out_path</span><span class="p">,</span> <span class="n">tmp_path</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">problem_cls</span><span class="p">,</span> <span class="n">bj</span><span class="p">,</span> <span class="n">is_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">bj</span><span class="o">.</span><span class="n">flags</span><span class="p">)</span>

        <span class="c1"># 2. Run image analysis workflow</span>
        <span class="n">bj</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">progress</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">statusComment</span><span class="o">=</span><span class="s2">&quot;Launching workflow...&quot;</span><span class="p">)</span>

        <span class="c1"># Add here the code for running the analysis script</span>

        <span class="c1"># 3. Upload data to BIAFLOWS</span>
        <span class="o">...</span>
        
        <span class="c1"># 4. Compute and upload metrics</span>
        <span class="o">...</span>

        <span class="c1"># 5. Pipeline finished</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>This wrapper handles the input parameters for you, providing the input images as <code class="docutils literal notranslate"><span class="pre">in_imgs</span></code>, et cetera. Then you add your commandline call between point 2 and 3, and possibly some preprocessing between point 1 and 2:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#add here the code for running the analysis script</span>
</pre></div>
</div>
<p>For example, from <a class="reference external" href="https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/blob/master/wrapper.py">Cellpose</a> container workflow:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>

<span class="c1"># 2. Run image analysis workflow</span>
<span class="n">bj</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">progress</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">statusComment</span><span class="o">=</span><span class="s2">&quot;Launching workflow...&quot;</span><span class="p">)</span>

<span class="c1"># Add here the code for running the analysis script</span>
<span class="n">prob_thresh</span> <span class="o">=</span> <span class="n">bj</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">prob_threshold</span>
<span class="n">diameter</span> <span class="o">=</span> <span class="n">bj</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">diameter</span>
<span class="n">cp_model</span> <span class="o">=</span> <span class="n">bj</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">cp_model</span>
<span class="n">use_gpu</span> <span class="o">=</span> <span class="n">bj</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">use_gpu</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Chosen model: </span><span class="si">{cp_model}</span><span class="s2"> | Channel </span><span class="si">{nuc_channel}</span><span class="s2"> | Diameter </span><span class="si">{diameter}</span><span class="s2"> | Cell prob threshold </span><span class="si">{prob_thresh}</span><span class="s2"> | GPU </span><span class="si">{use_gpu}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;python&quot;</span><span class="p">,</span> <span class="s2">&quot;-m&quot;</span><span class="p">,</span> <span class="s2">&quot;cellpose&quot;</span><span class="p">,</span> <span class="s2">&quot;--dir&quot;</span><span class="p">,</span> <span class="n">tmp_path</span><span class="p">,</span> <span class="s2">&quot;--pretrained_model&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{cp_model}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;--save_tif&quot;</span><span class="p">,</span> <span class="s2">&quot;--no_npy&quot;</span><span class="p">,</span> <span class="s2">&quot;--chan&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nuc_channel</span><span class="p">),</span> <span class="s2">&quot;--diameter&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{:f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">diameter</span><span class="p">),</span> <span class="s2">&quot;--cellprob_threshold&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{:f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">prob_thresh</span><span class="p">)]</span>
<span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using GPU!&quot;</span><span class="p">)</span>
    <span class="n">cmd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;--use_gpu&quot;</span><span class="p">)</span>
<span class="n">status</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span>

<span class="k">if</span> <span class="n">status</span><span class="o">.</span><span class="n">returncode</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running Cellpose failed, terminate&quot;</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Crop to original shape</span>
<span class="k">for</span> <span class="n">bimg</span> <span class="ow">in</span> <span class="n">in_imgs</span><span class="p">:</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">resized</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">bimg</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">imageio</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span><span class="n">bimg</span><span class="o">.</span><span class="n">filename_no_extension</span><span class="o">+</span><span class="s2">&quot;_cp_masks.tif&quot;</span><span class="p">))</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">:</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">imageio</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_path</span><span class="p">,</span><span class="n">bimg</span><span class="o">.</span><span class="n">filename</span><span class="p">),</span> <span class="n">img</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span><span class="n">bimg</span><span class="o">.</span><span class="n">filename_no_extension</span><span class="o">+</span><span class="s2">&quot;_cp_masks.tif&quot;</span><span class="p">),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_path</span><span class="p">,</span><span class="n">bimg</span><span class="o">.</span><span class="n">filename</span><span class="p">))</span>

<span class="c1"># 3. Upload data to BIAFLOWS</span>
</pre></div>
</div>
<p>We get the commandline parameters from <code class="docutils literal notranslate"><span class="pre">bj.parameters</span></code> (biaflows job) and provide that the <code class="docutils literal notranslate"><span class="pre">cmd</span></code> commandline string. Then we run it with <code class="docutils literal notranslate"><span class="pre">subprocess.run(cmd)</span></code> and check the <code class="docutils literal notranslate"><span class="pre">status</span></code>.</p>
<p>We use a <code class="docutils literal notranslate"><span class="pre">tmp_path</span></code> to store both input and output, then move the output to the <code class="docutils literal notranslate"><span class="pre">out_path</span></code> after the processing is done.</p>
<p>Also note that some preprocessing is done in step 1:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make sure all images have at least 224x224 dimensions</span>
<span class="c1"># and that minshape / maxshape * minshape &gt;= 224</span>
<span class="c1"># 0 = Grayscale (if input RGB, convert to grayscale)</span>
<span class="c1"># 1,2,3 = rgb channel</span>
<span class="n">nuc_channel</span> <span class="o">=</span> <span class="n">bj</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">nuc_channel</span>
<span class="n">resized</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">bfimg</span> <span class="ow">in</span> <span class="n">in_imgs</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="n">imageio</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="n">bfimg</span><span class="o">.</span><span class="n">filename</span><span class="p">),</span> <span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
<p>Another example is this <code class="docutils literal notranslate"><span class="pre">imageJ</span></code> <a class="reference external" href="https://github.com/Neubias-WG5/W_NucleiSegmentation3D-ImageJ/blob/master/wrapper.py">wrapper</a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>

<span class="c1"># 3. Call the image analysis workflow using the run script</span>
<span class="n">nj</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">progress</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">statusComment</span><span class="o">=</span><span class="s2">&quot;Launching workflow...&quot;</span><span class="p">)</span>

<span class="n">command</span> <span class="o">=</span> <span class="s2">&quot;/usr/bin/xvfb-run java -Xmx6000m -cp /fiji/jars/ij.jar ij.ImageJ --headless --console &quot;</span> \
            <span class="s2">&quot;-macro macro.ijm </span><span class="se">\&quot;</span><span class="s2">input=</span><span class="si">{}</span><span class="s2">, output=</span><span class="si">{}</span><span class="s2">, radius=</span><span class="si">{}</span><span class="s2">, min_threshold=</span><span class="si">{}</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">in_path</span><span class="p">,</span> <span class="n">out_path</span><span class="p">,</span> <span class="n">nj</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">ij_radius</span><span class="p">,</span> <span class="n">nj</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">ij_min_threshold</span><span class="p">)</span>
<span class="n">return_code</span> <span class="o">=</span> <span class="n">call</span><span class="p">(</span><span class="n">command</span><span class="p">,</span> <span class="n">shell</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="s2">&quot;/fiji&quot;</span><span class="p">)</span>  <span class="c1"># waits for the subprocess to return</span>

<span class="k">if</span> <span class="n">return_code</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">err_desc</span> <span class="o">=</span> <span class="s2">&quot;Failed to execute the ImageJ macro (return code: </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">return_code</span><span class="p">)</span>
    <span class="n">nj</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">progress</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">statusComment</span><span class="o">=</span><span class="n">err_desc</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">err_desc</span><span class="p">)</span>
    
</pre></div>
</div>
<p>Once again, just a commandline <code class="docutils literal notranslate"><span class="pre">--headless</span></code> call to <code class="docutils literal notranslate"><span class="pre">ImageJ</span></code>, wrapped in this Python script and this container.</p>
</div>
</div>
</div>
<div class="section" id="how-to-add-your-new-custom-workflow">
<h1>How to add your new custom workflow<a class="headerlink" href="#how-to-add-your-new-custom-workflow" title="Permalink to this headline"></a></h1>
<p>Building workflows like this will make them more <a class="reference external" href="https://www.go-fair.org/fair-principles/">FAIR</a> (also for <a class="reference external" href="https://fair-software.eu/about">software</a>) and uses best practices like code versioning and containerization!</p>
<p>Also take a look at our in-depth tutorial on adding a Cellprofiler pipeline as a workflow to OMERO Slurm Client.</p>
<p>Here is a shorter version:
Say you have a script in Python and you want to make it available on OMERO and Slurm.</p>
<p>These are the steps required:</p>
<ol class="arabic simple">
<li><p>Rewrite your script to be headless / to be executable on the commandline. This requires handling of commandline parameters as input.</p>
<ul class="simple">
<li><p>Make sure the I/O matches the Slurm job, see <a class="reference external" href="https://docs.python.org/3/library/io.html#module-io" title="Python 3.12"><span class="xref myst">previous chapter</span></a>.</p></li>
</ul>
</li>
<li><p>Describe these commandline parameters in a <code class="docutils literal notranslate"><span class="pre">descriptor.json</span></code> (see previous <a class="reference internal" href="#workflow-metadata-via-descriptorjson"><span class="xref myst">chapter</span></a>). E.g. <a class="reference external" href="https://doc.uliege.cytomine.org/dev-guide/algorithms/write-app#create-the-json-descriptor">like this</a>.</p></li>
<li><p>Describe the requirements / environment of your script in a <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code>, <a class="reference external" href="https://learnpython.com/blog/python-requirements-file/">like this</a>. Make sure to pin your versions for future reproducability!</p></li>
<li><p>Package your script in a Docker container. E.g. <a class="reference external" href="https://www.docker.com/blog/how-to-dockerize-your-python-applications/">like this</a>.</p>
<ul class="simple">
<li><p>Note: Please watch out for the pitfalls of reproducability with Dockerfiles: <a class="reference external" href="https://pythonspeed.com/articles/dockerizing-python-is-hard/">Always version your packages!</a>.</p></li>
</ul>
</li>
<li><p>Publish your source code, Dockerfile and descriptor.json to a new Github repository (free for public repositories). You can generate a new repository <a class="reference external" href="https://docs.github.com/en/repositories/creating-and-managing-repositories/creating-a-repository-from-a-template">from template</a>, using <a class="reference external" href="https://github.com/Neubias-WG5/W_Template">this template</a> provided by Neubias (BIAFLOWS). Then replace the input of the files with yours.</p></li>
<li><p>(Recommended) Publish a new version of your code (e.g. v1.0.0). E.g. <a class="reference external" href="https://docs.github.com/en/repositories/releasing-projects-on-github/managing-releases-in-a-repository">like this</a>.</p></li>
<li><p>Publish your container on Dockerhub (free for public repositories), using the same versioning as your source code. <a class="reference external" href="https://docs.docker.com/get-started/publish-your-own-image/">Like this</a> from Windows Docker or <a class="reference external" href="https://www.geeksforgeeks.org/docker-publishing-images-to-docker-hub/">like this</a> from a commandline.</p>
<ul class="simple">
<li><p>(Recommended) Please use a tag that equals your repository version, instead of <code class="docutils literal notranslate"><span class="pre">latest</span></code>. This improves reproducability!</p></li>
<li><p>(Optional) this library grabs <code class="docutils literal notranslate"><span class="pre">latest</span></code> if the code repository is given no version, but the <code class="docutils literal notranslate"><span class="pre">master</span></code> branch.</p></li>
</ul>
</li>
<li><p>Follow the steps from the previous <a class="reference internal" href="#how-to-add-an-existing-workflow"><span class="xref myst">chapter</span></a>:</p>
<ul class="simple">
<li><p>Add details to <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code></p></li>
<li><p>Run <code class="docutils literal notranslate"><span class="pre">SlurmClient.from_config(init_slurm=True)</span></code> (e.g. the init environment script.)</p></li>
</ul>
</li>
</ol>
</div>
<div class="section" id="slurm-jobs">
<h1>Slurm jobs<a class="headerlink" href="#slurm-jobs" title="Permalink to this headline"></a></h1>
<div class="section" id="generating-jobs">
<h2>Generating jobs<a class="headerlink" href="#generating-jobs" title="Permalink to this headline"></a></h2>
<p>By default, <code class="docutils literal notranslate"><span class="pre">omero_slurm_client</span></code> will generate basic slurm jobs for each workflow, based on the metadata provided in <code class="docutils literal notranslate"><span class="pre">descriptor.json</span></code> and a <a class="reference internal" href="#./resources/job_template.sh"><span class="xref myst">job template</span></a>.
It will replace <code class="docutils literal notranslate"><span class="pre">$PARAMS</span></code> with the (non-<code class="docutils literal notranslate"><span class="pre">cytomine_</span></code>) parameters given in <code class="docutils literal notranslate"><span class="pre">descriptor.json</span></code>. See also the <a class="reference internal" href="#parameters"><span class="xref myst">Parameters</span></a> section below.</p>
</div>
<div class="section" id="how-to-add-your-own-slurm-job">
<h2>How to add your own Slurm job<a class="headerlink" href="#how-to-add-your-own-slurm-job" title="Permalink to this headline"></a></h2>
<p>You could change the <a class="reference internal" href="#./resources/job_template.sh"><span class="xref myst">job template</span></a> and generate new jobs, by running <code class="docutils literal notranslate"><span class="pre">SlurmClient.from_config(init_slurm=True)</span></code> (or <code class="docutils literal notranslate"><span class="pre">slurmClient.update_slurm_scripts(generate_jobs=True)</span></code>)</p>
<p>Or you could add your jobs to a <a class="reference external" href="https://github.com/TorecLuik/slurm-scripts">Github repository</a> and reference this in <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code>, both in the field <code class="docutils literal notranslate"><span class="pre">slurm_script_repo</span></code> and every <code class="docutils literal notranslate"><span class="pre">&lt;workflow&gt;_job</span></code>:</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------</span>
<span class="c1"># REPOSITORIES</span>
<span class="c1"># -------------------------------------</span>
<span class="c1"># A (github) repository to pull the slurm scripts from.</span>
<span class="c1">#</span>
<span class="c1"># Note: </span>
<span class="c1"># If you provide no repository, we will generate scripts instead!</span>
<span class="c1"># Based on the job_template and the descriptor.json</span>
<span class="c1">#</span>
<span class="na">slurm_script_repo</span><span class="o">=</span><span class="s">https://github.com/TorecLuik/slurm-scripts</span>

<span class="k">[MODELS]</span>
<span class="c1"># -------------------------------------</span>
<span class="c1"># Model settings</span>
<span class="c1"># -------------------------------------</span>
<span class="c1"># ...</span>
<span class="c1"># -------------------------------------</span>
<span class="c1"># CELLPOSE SEGMENTATION</span>
<span class="c1"># -------------------------------------</span>
<span class="c1"># The path to store the container on the slurm_images_path</span>
<span class="na">cellpose</span><span class="o">=</span><span class="s">cellpose</span>
<span class="c1"># The (e.g. github) repository with the descriptor.json file</span>
<span class="na">cellpose_repo</span><span class="o">=</span><span class="s">https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/tree/v1.2.7</span>
<span class="c1"># The jobscript in the &#39;slurm_script_repo&#39;</span>
<span class="na">cellpose_job</span><span class="o">=</span><span class="s">jobs/cellpose.sh</span>
</pre></div>
</div>
<p>You can update the jobs by calling <code class="docutils literal notranslate"><span class="pre">slurmClient.update_slurm_scripts()</span></code>, which will pull the repository(‘s default branch).</p>
<p>This might be useful, for example if you have other hardware requirements for your workflow(s) than the default job asks for, or if you want to run more than just 1 singularity container.</p>
<div class="section" id="parameters">
<h3>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline"></a></h3>
<p>The library will provide the parameters from your <code class="docutils literal notranslate"><span class="pre">descriptor.json</span></code> as environment variables to the call. E.g. <code class="docutils literal notranslate"><span class="pre">set</span> <span class="pre">DIAMETER=0;</span> <span class="pre">sbatch</span> <span class="pre">...</span></code>.</p>
<p>Other environment variables provided are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DATA_PATH</span></code></p>
<ul>
<li><p>Made of <code class="docutils literal notranslate"><span class="pre">&lt;slurm_data_path&gt;/&lt;input_folder&gt;</span></code>. The base dir for data folders for this execution. We expect it to contain <code class="docutils literal notranslate"><span class="pre">/data/in</span></code>, <code class="docutils literal notranslate"><span class="pre">/data/in</span></code> and <code class="docutils literal notranslate"><span class="pre">/data/in</span></code> folders in our template and data transfer setup.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">IMAGE_PATH</span></code></p>
<ul>
<li><p>Made of <code class="docutils literal notranslate"><span class="pre">&lt;slurm_images_path&gt;/&lt;model_path&gt;</span></code>, as described in <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">IMAGE_VERSION</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SINGULARITY_IMAGE</span></code></p>
<ul>
<li><p>Already uses the <code class="docutils literal notranslate"><span class="pre">IMAGE_VERSION</span></code> above, as <code class="docutils literal notranslate"><span class="pre">&lt;container_name&gt;_&lt;IMAGE_VERSION&gt;.sif</span></code></p></li>
</ul>
</li>
</ul>
<p>We (potentially) override the following Slurm job settings programmatically:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--mail-user={email}</span></code> (optional)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--time={time}</span></code> (optional)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--output=omero-%4j.log</span></code> (mandatory)</p></li>
</ul>
<p>We could add more overrides in the future, and perhaps make them available as global configuration variables in <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code>.</p>
</div>
</div>
</div>
<div class="section" id="batching">
<h1>Batching<a class="headerlink" href="#batching" title="Permalink to this headline"></a></h1>
<p>We can simply use <code class="docutils literal notranslate"><span class="pre">Slurm</span></code> for running your workflow 1:1, so 1 job to 1 workflow. This could speed up your workflow already, as <code class="docutils literal notranslate"><span class="pre">Slurm</span></code> servers are likely equipped with strong CPU and GPU.</p>
<p>However, <code class="docutils literal notranslate"><span class="pre">Slurm</span></code> is also built for parallel processing on multiple (or the same) servers. We can accomplish this by running multiple jobs for 1 workflow. This is simple for <a class="reference external" href="https://en.wikipedia.org/wiki/Embarrassingly_parallel#:~:text=In%20parallel%20computing%2C%20an%20embarrassingly,a%20number%20of%20parallel%20tasks.">embarrassingly parallel</a> tasks, like segmenting multiple images: just provide each job with a different set of input images. If you have 100 images, you could run 10 jobs on 10 images and (given enough resources available for you on Slurm) that could be 10x faster. In theory, you could run 1 job per image, but at some point you run into the overhead cost of Slurm (and OMERO) and it might actually slow down again (as you incur this cost a 100 times instead of 10 times).</p>
</div>
<div class="section" id="using-the-gpu-on-slurm">
<h1>Using the GPU on Slurm<a class="headerlink" href="#using-the-gpu-on-slurm" title="Permalink to this headline"></a></h1>
<p>Note, the <a class="reference internal" href="#./resources/job_template.sh"><span class="xref myst">default</span></a> Slurm job script will not request any GPU resources.</p>
<p>This is because GPU resources are expensive and some programs do not work with GPU.</p>
<p>We can instead <em>enable</em> the use of GPU by either providing our own Slurm job scripts, or setting an override value in <code class="docutils literal notranslate"><span class="pre">slurm-config.ini</span></code>:</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------</span>
<span class="c1"># CELLPOSE SEGMENTATION</span>
<span class="c1"># -------------------------------------</span>
<span class="c1"># The path to store the container on the slurm_images_path</span>
<span class="na">cellpose</span><span class="o">=</span><span class="s">cellpose</span>
<span class="c1"># The (e.g. github) repository with the descriptor.json file</span>
<span class="na">cellpose_repo</span><span class="o">=</span><span class="s">https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/tree/v1.2.7</span>
<span class="c1"># The jobscript in the &#39;slurm_script_repo&#39;</span>
<span class="na">cellpose_job</span><span class="o">=</span><span class="s">jobs/cellpose.sh</span>
<span class="c1"># Override the default job values for this workflow</span>
<span class="c1"># Or add a job value to this workflow</span>
<span class="c1"># If you don&#39;t want to override, comment out / delete the line.</span>
<span class="c1"># Run CellPose Slurm with 10 GB GPU</span>
<span class="na">cellpose_job_gres</span><span class="o">=</span><span class="s">gpu:1g.10gb:1</span>
</pre></div>
</div>
<p>In fact, any <code class="docutils literal notranslate"><span class="pre">..._job_...=...</span></code> configuration value will be forwarded to the Slurm commandline.</p>
<p>Slurm commandline parameters override those in the script, so the above one requests 1 10GB gpu for Cellpose.</p>
<p>E.g. you could also set the time limit higher:</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------</span>
<span class="c1"># CELLPOSE SEGMENTATION</span>
<span class="c1"># -------------------------------------</span>
<span class="c1"># The path to store the container on the slurm_images_path</span>
<span class="na">cellpose</span><span class="o">=</span><span class="s">cellpose</span>
<span class="c1"># The (e.g. github) repository with the descriptor.json file</span>
<span class="na">cellpose_repo</span><span class="o">=</span><span class="s">https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/tree/v1.2.7</span>
<span class="c1"># The jobscript in the &#39;slurm_script_repo&#39;</span>
<span class="na">cellpose_job</span><span class="o">=</span><span class="s">jobs/cellpose.sh</span>
<span class="c1"># Override the default job values for this workflow</span>
<span class="c1"># Or add a job value to this workflow</span>
<span class="c1"># If you don&#39;t want to override, comment out / delete the line.</span>
<span class="c1"># Run with longer time limit</span>
<span class="na">cellpose_job_time</span><span class="o">=</span><span class="s">00:30:00</span>
</pre></div>
</div>
<p>Now the CellPose job should run for maximum of 30 minutes, instead of the default.</p>
</div>
<div class="section" id="transfering-data">
<h1>Transfering data<a class="headerlink" href="#transfering-data" title="Permalink to this headline"></a></h1>
<p>We have added methods to this library to help with transferring data to the <code class="docutils literal notranslate"><span class="pre">Slurm</span></code> cluster, using the same SSH connection (via SCP or SFTP).</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">slurmClient.transfer_data(...)</span></code></p>
<ul>
<li><p>Transfer data to the Slurm cluster</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">slurmClient.unpack_data(...)</span></code></p>
<ul>
<li><p>Unpack zip file on the Slurm cluster</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">slurmClient.zip_data_on_slurm_server(...)</span></code></p>
<ul>
<li><p>Zip data on the Slurm cluster</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">slurmClient.copy_zip_locally(...)</span></code></p>
<ul>
<li><p>Transfer (zip) data from the Slurm cluster</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">slurmClient.get_logfile_from_slurm(...)</span></code></p>
<ul>
<li><p>Transfer logfile from the Slurm cluster</p></li>
</ul>
</li>
</ul>
<p>And more; see the docstring of <code class="docutils literal notranslate"><span class="pre">SlurmClient</span></code> and example OMERO scripts.</p>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to Omero Slurm Client’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tutorial_link.html" class="btn btn-neutral float-right" title="Cellprofiler tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, T.T.Luik.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>